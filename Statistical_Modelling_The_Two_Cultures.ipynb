{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Modelling: The Two Cultures\n",
    "\n",
    "## Review of the article, by Shrikant Agrawal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract\n",
    "This article provides a critical review of the paper (Breiman, 2001), Statistical Modelling: Two cultures. The article first provides a concise summary of the paper, followed by a short summary of the comments by Cox and Efron on the paper. Next, I have provided my comments on all three arguments and finally, my standpoint on the topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.kdnuggets.com/images/breiman-2-cultures.jpg?raw=true\"  align = \"center\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of the Paper\n",
    "### Statistical model: The two cultures\n",
    "In his paper, Breiman first introduces the statistical analysis with two goals: prediction and information. Next, he provides his viewpoint about the statistical community (of his time) that it is largely divided as two cultures based on the methods of how they approach the said goals. According to Breiman, data modelling culture tries to identify the relationship among the variables by fitting standard data models to the data. Then, he defines the algorithmic modelling culture where focus of the process is to identify a function or an algorithm that accurately predicts the response variable for given inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breiman provides three main arguments against data modelling culture claiming that:\n",
    "1. Excessive reliability on data models with complex datasets lead to questionable conclusions.\n",
    "2. Statisticians regard algorithmic models as out of scope since they don’t follow probabilistic basis, even when they perform better than the data modelling approach.\n",
    "3. Data Modelling culture hinders the progress of statistical analysis by preventing statisticians to explore new challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To support his arguments, he provided a detailed exposition of various projects he has worked on as a free-lance statistical consultant as well as an academic statistician.\n",
    "Leo’s explained his affinity towards algorithmic modelling because of its high flexibility and astonishing accuracy in predictions. When he returned to academic side, he was surprised to observe that almost all statisticians had a monotonous viewpoint about algorithmic modelling as non-statistical. Breiman calls the blind trust on data models as a strange phenomenon. He continues his argument against data modelling culture by talking about the shortcomings of the approaches to validate the models. He mentions that goodness-of-fit tests and residual analysis fail to provide consistent results for higher dimensional data. Here, he asks for better validation tests and provides Cross Validation as a better approach. Next, he comments on the predictability of the models. He claims that anything that cannot be explained by a data model is regarded as noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breiman then advocates for algorithmic modelling by using three lessons: Rashomon Effect, Occam’s Razor and Bellman’s curse of Dimensionality. First, he explains that the underlying nature of data may not be possible to be explained by one data model and therefore, the multiplicity of good models is required for a better prediction. He talks about various machine learning approaches like neural networks, random forests, bagging and boosting that follow the same principle to provide A+ interpretability and a relatively higher prediction. Then, he comments on the Occam’s dilemma and provides his conclusions that Accuracy generally requires more complex prediction methods and that simple and interpretable data models cannot make most accurate predictions. Finally, he talks about the curse of dimensionality where he argues that dimensionality is only a curse for data models and in fact a blessing for the algorithms. He provides various examples where increasing the dimensions can provide better predictions in cases of SVMs and Random forest methods.\n",
    "He concludes by reiterating the goals of statistical learning by talking about the advantages of algorithmic modelling and the flaws of data modelling in achieving the goals. He suggests that an algorithmic model with higher accuracy and lower interpretability can provide better insights about black box than a simple data model with low accuracy. Finally, he urges the statistical community by the explaining that the focus of modelling should be on the problem and the data and not on how to fit a data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key points\n",
    "### Breiman\n",
    "• Excessive reliability on data models with complex datasets lead to questionable conclusions.\n",
    "\n",
    "• Validation methods for data modelling are primitive and less reliable with increasing complexity of the data.\n",
    "\n",
    "• An algorithmic model with higher accuracy and lower interpretability can provide better insights about the underlying mechanism than a simple data model with low accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My review and comments\n",
    "Breiman claims that the statistical community favours data modelling approach blindly due to its interpretability and calls this viewpoint as narrow. I disagree with this claim as it is highly bias against data modelling approach and think that this claim is more of a prejudiced comment rather than a well-reasoned statement. The paper describes in length about the shortcomings of data modelling approach in terms of predictability and validation of the models to which I agree. I believe that with evolution of data from structured format to Big Data demands a great evolution in analytical and statistical tools. However, the paper fails to provide sufficient evidence to back up Breiman’s claim that the community only favours the data modelling approach. In addition, it also provides a biased picture to favour algorithmic approaches and doesn’t do justice to the probabilistic approaches for statistical analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, Breiman talks about the limitations of data modelling approaches and suggests that goodness of fit tests and residual analysis tests doesn’t guaranty model validity. I agree with this statement to a fair point. In Data Modelling culture, the model’s explainability relies on how well does the model fit the data and anything else that doesn’t agree with model parameters is regarded as noise. According to me this statement may not be true always, but it certainly provides a candid representation of current methods of model validation. Thankfully, this tradition has changed. Today, when a statistical paper is published, author explicitly provides the dataset, the conditions of experiment, goals and methods of reproduction of the results for everyone to understand the scope of the paper. This change has provided an extra layer of validation for each novel approach. Breiman further advocates for Cross Validation and claims that it provides an unbiased estimate of predictive accuracy which is true even today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breiman insists that an algorithmic model with higher accuracy can provide better insights about the black box than a simple data model with low accuracy. Upon careful evaluation of the complete paper, I call this claim as a biased representation of true facts. Breiman has fell into his own anecdote that “If all a man has is a hammer, then every problem looks like a nail.” In other words, he focusses more on the predictive capabilities of the algorithm and talks less about what’s inside the black box. The goal of the statistical analysis shouldn’t just focus on the prediction but also on the information. Furthermore, with increasing complexity of the data, one cannot guaranty that empirical methods would always provide a better outcome than data models. A better understanding of the nature of data is extremely relevant for both approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments by Cox (Summarised):\n",
    "\n",
    "• Excluding the algorithmic decision making as a part of statistical analysis is unwise.\n",
    "\n",
    "• To approach a problem, look that the underlying information and build a hypothesis. Then create a model that best suits the hypothesis.\n",
    "\n",
    "• Prediction is not the only goal of statistical learning and interpretability of the process is equally necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My review and comments\n",
    "Cox’s comments on Breiman’s paper are highly informative and well-reasoned. He acknowledges Breiman’s work as thought provoking and insightful. He appreciates the wide range of projects and examples provided in the paper where algorithmic models provide better performance that data models. He understands the changing trends in the statistical analysis and therefore claims that not including algorithmic approaches as statistical analysis is an unwise decision. I agree with this statement completely. Additionally, I believe that with emergence of new fields like Data Science, where mathematicians, statisticians and computer programmers come under one roof to solve a problem, we can expect stark changes in methodologies and perspective in near future.\n",
    "\n",
    "Cox then counterpoints Breiman’s idea of judging the performance of a model by just observing the predictability. He backs up his argument by providing examples where best predicting algorithms cannot predict the true outcomes in long term. He continues his argument by talking about the scope of the predictions. If the predictions are localised and the similar to training data, then the answer of which model is best would depend on the context and not just on the predictive power. Although he agrees that empirical approaches work better in short term and complex projects like weather forecasting, interpretability will always be valued in situations that require stability, for examples in clinical trials. I agree with Cox’s standpoint. The overall goal of statistical analysis should not be limited to higher predictability but also the information about what’s going inside the black box.\n",
    "Cox then provides his insights on both sides of statistical analysis and suggests that formal methods and evaluation tools are applicable perfectly for ideal scenarios and may not perform with similar robustness in case of real data. This doesn’t mean to mark them as useless. This statement is applicable to all the scientific fields. For example, classical physics works extremely well with macroscopic objects while fails to explain anything at quantum level. This doesn’t make it useless. Cox explains this notion by saying that a hypothesis is required based on the domain knowledge and the nature of data making any model.\n",
    "\n",
    "Cox concludes by disagreeing with Breiman’s claim of algorithmic approaches being always better performing than data models and deems his argument as pessimistic. I agree. There is a strong requirement for a framework that balances the predictability of empirical approaches and stability of data modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments by Efron (Summarised):\n",
    "\n",
    "• We need to keep an open mind while tackling the rapid evolution in experimental design and invite new ideas without looking at their source.\n",
    "\n",
    "• Overparameterizing in the algorithmic approaches lead to the overfitting and contradicts the Bias Variance trade-off.\n",
    "\n",
    "• It is important to learn about the underlying mechanism of how data was generated before creating a predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My review and comments\n",
    "Efron takes a defensive stance against Breiman and calls his paper as lacking of scientific insights to favour the algorithmic modelling. This is incorrect in entirety as Breiman’s paper provides plethora of statistical experiments and talks about a wide range of challenges and processes that brings out stimulating inferences.\n",
    "Efron first agrees on one key idea from Breiman’s paper that with change in experimental design and increasing volume of sample sizes, we need better approaches to tackle the challenge and agrees to the openness of new ideas no matter the source. I agree with his statement. I believe that Data Science is a field of exploration where ideas from all the disciplines are cherished equally. Cross-disciplinary ideas often lead to astonishing discoveries. For example, Fisher, being a statistician, has also contributed greatly in the fields of biology and genetics.\n",
    "\n",
    "\n",
    "Efron then explains his disagreement with Breiman on algorithmic modelling by talking about Bias Variance trade-off. He mentions that overparameterizing in algorithmic approaches lead to overfitting and that it is fundamentally against the basic rules of statistical learning. He explains that data centric approaches will always provide higher accuracy but these results are limited to the scope of data. In my opinion, this statement is correct since any extrapolation based on empirical approaches outside the scope of data is unreliable. With increasing complexity of data, one cannot guaranty the success of any model beyond their scopes. This is true for both cultures. However, my experiences with both modelling approaches suggest that the flexibility of algorithmic processes provides an upper hand to assess unexplored terrains as compared to the rigidity of the data modelling approaches. In the fields of image recognition and speech recognition, it is highly likely that a complex model provides more information about the black box than a data model.\n",
    "\n",
    "\n",
    "Efron concludes by commenting that Breiman has exaggerated the role of prediction in statistical learning and has undermined the current community’s interest in finding better predicting models. It is fairly said. The goal of statistical learning should be balanced between information and prediction. Favouring any one goal over other is unwise. The community should focus on opening the black boxes to build a better model rather than to consider it as an absolute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Viewpoint: Promoting Interpretable Machine Learning.\n",
    "Breiman’s paper can be considered as one of the thoughts that lay the bedrocks on which the Data Science is built today. Data Science provides a process-oriented approach ensures that the end result of modelling is meaningful as well as accurate enough to answer the questions posed by the domain. This means that one has to understand the scope and working of the algorithms we develop to a reasonable extent so as to minimise the hidden flaws. I therefore, root for a process called Interpretable Machine Learning (IML) (Molnar, 2019), with a focus on three core principles of Data Science: Predictability, Computability and Stability. My views are inspired from the works of Prof. Bin Yu and her presentation on Veridical Data Science (Yu and Kumbier, 2020).\n",
    "Breiman claims that if we can accurately predict the outcomes from the black box, it can provide more information about what’s inside the box. Cox and Efron counterpoint his arguments by explaining that the nature of black box needs to be understood. Interpretable Machine Learning (IML) approach ensures that evaluating any modelling approach has to cover both fronts, i.e. interpretability and predictability. IML thus, bridges Breiman’s two cultures by taking the best of both worlds. IML ensures that the model convey the accurate information in the context of domain knowledge and human understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When developing a model, one has to ensure the balance between predictability, computability and stability. Yu talks about the importance of “judgement calls” at every step to shake the process enough to maintain the robustness (Yu and Kumbier, 2019). However, while checking stability, one should not deviate from the underlying problem and should ensure that the predictability and computability of the process is maintained. Yu also talks about the “faithful” interpretation of algorithms, to which I fully agree. It is highly important that the end results from a process are explainable enough to stimulate human understanding and yet accurate enough to build up on current understanding in the domain. On computability, I have a dual standpoint. Yu claims that a process with high predictability and stability but little execution cannot help in answering the questions. This may be true in current situation but our processes should not be limited by the technology of our times. Instead, it should motivate the community to build better machines to satisfy the need of the algorithms. That being said, if the goal is to get the answers today, the computability of the model matters as much as the other principles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, I want to borrow Breiman’s analogy of Rashomon Effect to talk about PCS framework and interpretable Machine Learning (Breiman, 2001). When developing a model, one has to explore all sides of the problem to provide a correct solution. Furthermore, we cannot undermine either of the core principles of Data Science to improve the model. The community must ensure to build models that follows data science process with predictability, computability and stability at its core. Deviation from either of these principles may lead to uncertainty in the results and render the statistical learning unfruitful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "• Breiman, L., 2001. Statistical Modeling: The Two Cultures (with comments and a rejoinder by the author). Statistical Science, 16(3), pp.199-231.\n",
    "\n",
    "• Stuart, M., 2019. The Actual Difference Between Statistics And Machine Learning. [online] towardsdatascience. Available at: <https://towardsdatascience.com/the-actual-difference-between-statistics-and-machine-learning-64b49f07ea3> [Accessed 1 September 2020].\n",
    "\n",
    "• Yu, B. and Kumbier, K., 2020. Veridical data science. Proceedings of the National Academy of Sciences, 117(8), pp.3920-3929.\n",
    "\n",
    "• Yu, B. and Kumbier, K., 2019. Veridical data science. Proceedings of the National Academy of Sciences, 117(8), pp.3920-3929.\n",
    "\n",
    "• Molnar, C., 2019. Interpretable Machine Learning. A Guide For Making Black Box Models Explainable. Github."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
